{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbayes.sample\n",
    "import cbayes.distributions\n",
    "import cbayes.solve\n",
    "import numpy as np\n",
    "import ipywidgets as wd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sstats\n",
    "import scipy.spatial as spat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following linear map $Q_s: \\mathbb{R}^2 \\to \\mathbb{R}^2$ is defined to have skewness $s$ at all $\\lambda \\in \\Lambda$.  \n",
    "\n",
    "$$\n",
    "Q_s(\\lambda) = \\lbrace \\, \\lambda_1, \\; \\lambda_1 \\sqrt{s^2 - 1} + \\lambda_2 \\, \\rbrace\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Identities\n",
    "Let $\\lambda$ denote an arbitrary Gaussian random variable with mean $\\mu_\\lambda$ and covariance $\\Sigma_\\lambda$,\n",
    "$$\n",
    "\\lambda \\sim N\\left(\\mu_\\lambda, \\Sigma_\\lambda\\right).\n",
    "$$\n",
    "Then, for a matrix $A$, \n",
    "$$\n",
    "A\\lambda \\sim N\\left(A\\mu_\\lambda,\\, A\\Sigma_\\lambda A^T\\right)\n",
    "$$\n",
    "Let $\\eta = A\\lambda + e$, where $e\\sim N(0,\\Sigma_e)$,   \n",
    "then the posterior $p(\\lambda | \\eta)$ is given by\n",
    "\n",
    "$$\n",
    "p(\\lambda | \\eta=\\bar{\\eta}) = N\\left(\\hat{\\mu}, \\hat{\\Sigma}\\right),\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\hat{\\mu} = \\mu_\\lambda + \\Sigma_\\lambda A^T\\left(A\\Sigma_\\lambda A^T + \\Sigma_e\\right)^{-1}\\left(\\bar{\\eta} - A\\mu_\\lambda\\right)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\hat{\\Sigma} = \\Sigma_\\lambda - \\Sigma_\\lambda A^T\\left(A\\Sigma_\\lambda A^T + \\Sigma_e\\right)^{-1}A\\Sigma_\\lambda\n",
    "$$\n",
    "\n",
    "[These notes](https://cs.nyu.edu/~roweis/notes/gaussid.pdf) by Sam Roweis also provide some useful identities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that generates an arbitrarily ill-condidtioned 2-2 map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(skew):\n",
    "    # this function makes a linear map whos first component is the x-unit vector\n",
    "    # and each subsequent component is a norm-1 vector satisfying the property\n",
    "    # that the 2-2 map made from it and the aforementioned unit vector is a map\n",
    "    # with skewness in skew_range, which is a list of desired skewnesses   \n",
    "    # TODO currently this map only works for 2-D input space     \n",
    "    \n",
    "    def my_model(parameter_samples):\n",
    "        Q_map = skewmat(skew)\n",
    "        QoI_samples = np.dot(parameter_samples, np.transpose(Q_map))\n",
    "#         QoI_samples = Q_map@parameter_samples.T\n",
    "        return QoI_samples\n",
    "    return my_model\n",
    "\n",
    "def skewmat(skew):\n",
    "    Q_map = [ [1.0, 0.0] ] # all map components have the same norm, rect_size to have measures of events equal btwn spaces.\n",
    "    Q_map.append( [np.sqrt(skew**2 - 1), 1] ) # taken with the first component, this leads to a 2-2 map with skewsness 's'\n",
    "    Q_map = np.array( Q_map )\n",
    "    return Q_map\n",
    "\n",
    "def gauss_sol(prior_mean, prior_std, data_std, A, data):\n",
    "    if type(prior_mean) is int:\n",
    "        prior_mean = [prior_mean, prior_mean]\n",
    "    if type(prior_mean) is float:\n",
    "        prior_mean = [prior_mean, prior_mean]\n",
    "    if type(prior_mean) is list:\n",
    "        prior_mean = np.array(prior_mean).reshape(-1,1)\n",
    "    if type(prior_std) is list:\n",
    "        prior_std = np.array(prior_std).reshape(-1,1)\n",
    "    if type(data_std) is list:\n",
    "        data_std = np.array(data_std).reshape(-1,1)\n",
    "    prior_cov = prior_std*prior_std*np.eye(2) \n",
    "    data_cov = data_std*data_std*np.eye(2) \n",
    "    \n",
    "    ASA = A@prior_cov@A.T\n",
    "    \n",
    "    precision = np.linalg.inv(ASA + data_cov)\n",
    "    kahlman_update = (prior_cov@A.T@precision)\n",
    "    post_mean = prior_mean + kahlman_update@(data - A@prior_mean)\n",
    "    post_cov = prior_cov - kahlman_update@A@prior_cov\n",
    "    \n",
    "    return prior_mean, prior_cov, post_mean, post_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Analytical Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = skewmat(1.01)\n",
    "# # print(A)\n",
    "# data_std = 0.25\n",
    "# prior_std = 1\n",
    "# prior_mean = 0\n",
    "# lam_true = np.array([0.0, 0.0])\n",
    "# obs_data = A@lam_true.T + data_std*np.random.randn(2)\n",
    "\n",
    "# prior_mean, prior_cov, post_mean, post_cov = gauss_sol(prior_mean, prior_std, data_std, A, obs_data.reshape(-1,1) )\n",
    "# print(post_mean.T,'\\n')\n",
    "# print(post_cov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the contours of this vector-valued map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate samples and map them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(num_samples=5000, skew=1, prior_x=0.0, prior_y=0.0, prior_std = 1.0, data_std = 0.25, color_map = 'jet', num_levels = 40, seed=12):\n",
    "    fsize=16 # font size\n",
    "    vmin, vmax = 0, None # height bounds for filled contours\n",
    "    pbound = 1.0 # parameter space bounds\n",
    "    dbound = 2.0  # data space bound\n",
    "    prior_alpha = 0.15 # transparency of prior contours\n",
    "    true_posterior_alpha = 0.3 # transparency for the contours of the true solution\n",
    "    num_plot_pts = 100 # resoltion for 1-D plots\n",
    "    show_slice = True # messy - show slice through middle of axis to interrogate posterior\n",
    "    normalize_marginals = False # normalizing the marginals (dividing the )\n",
    "    if normalize_marginals:\n",
    "        maxht = 0.15 # max y-axis height\n",
    "        vline_ht = 0.05 # height of vertical bar\n",
    "    else:\n",
    "        maxht = 350\n",
    "        vline_ht = 100 # shows truth\n",
    "    print(\"Working....\")\n",
    "    model = make_model(skew)\n",
    "    lam_true = np.array([0.0, 0.0])\n",
    "    obs_data = model(lam_true)\n",
    "    np.random.seed(seed)\n",
    "    obs_data_noisy = obs_data + data_std*np.random.randn(2)\n",
    "    mse_fun = cbayes.sample.MSE_generator(model, obs_data_noisy, data_std)\n",
    "    \n",
    "    # ANALYTICAL SOLUTION\n",
    "    prior_mean = np.array([prior_x, prior_y])\n",
    "    A = skewmat(skew)\n",
    "    prior_mean, prior_cov, post_mean, post_cov = gauss_sol(prior_mean, prior_std, data_std, A, obs_data_noisy)\n",
    "\n",
    "    s_input_set = cbayes.sample.sample_set(size=(num_samples, 2))\n",
    "    s_input_set.set_dist(dim=0, distribution='normal', kwds={'loc': prior_mean[0], 'scale': prior_std})\n",
    "    s_input_set.set_dist(dim=1, distribution='normal', kwds={'loc': prior_mean[1], 'scale': prior_std})\n",
    "    input_samples = s_input_set.generate_samples(seed=seed)\n",
    "    \n",
    "    output_samples_vector_valued = model(input_samples)\n",
    "    output_samples_scalar_valued = mse_fun(input_samples)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### VECTOR PROBLEM\n",
    "    s_output_set_vector_valued = cbayes.sample.sample_set(size=(num_samples, 2))\n",
    "    s_output_set_vector_valued.samples = output_samples_vector_valued\n",
    "    p_set_vector = cbayes.sample.problem_set(s_input_set, s_output_set_vector_valued)\n",
    "    # Set observed \n",
    "    p_set_vector.set_observed_dist(dim=0, dist='normal', \n",
    "                                   kwds={'loc': obs_data_noisy[0], 'scale': data_std})\n",
    "    p_set_vector.set_observed_dist(dim=1, dist='normal', \n",
    "                                   kwds={'loc': obs_data_noisy[1], 'scale': data_std})\n",
    "    p_set_vector.model = model\n",
    "    \n",
    "    p_set_vector.compute_pushforward_dist()\n",
    "    p_set_vector.set_ratio()\n",
    "    \n",
    "    cbayes.solve.problem(p_set_vector)\n",
    "    accepted_inputs_vector = p_set_vector.input.samples[p_set_vector.accept_inds,:]\n",
    "    print('num accepted for vector-valued:', len(accepted_inputs_vector), \n",
    "          'mean: %2.4f, %2.4f'%(np.mean(accepted_inputs_vector[:,0]), np.mean(accepted_inputs_vector[:,1])), \n",
    "          'sd: %2.4f, %2.4f'%(np.std(accepted_inputs_vector[:,0]), np.std(accepted_inputs_vector[:,1])) )\n",
    "\n",
    "    \n",
    "    #### SCALAR PROBLEM\n",
    "    s_output_set_scalar_valued = cbayes.sample.sample_set(size=(num_samples, 1))\n",
    "    s_output_set_scalar_valued.samples = output_samples_scalar_valued\n",
    "    p_set_scalar = cbayes.sample.problem_set(s_input_set, s_output_set_scalar_valued)\n",
    "    # Set observed \n",
    "    num_observations = 10 # NOT TO BE CHANGED\n",
    "    p_set_scalar.set_observed_dist('gamma', {'a':num_observations/2.0, 'scale':2.0/num_observations}, dim=0)\n",
    "    p_set_scalar.model = mse_fun\n",
    "    \n",
    "#     p_set_scalar.compute_pushforward_dist(method='sk', kwds={'bandwidth': 0.1}) ############################################################################\n",
    "    p_set_scalar.compute_pushforward_dist()\n",
    "    p_set_scalar.set_ratio()\n",
    "    \n",
    "    cbayes.solve.problem(p_set_scalar)\n",
    "    accepted_inputs_scalar = p_set_scalar.input.samples[p_set_scalar.accept_inds,:]\n",
    "    print('num accepted for scalar-valued:', len(accepted_inputs_scalar), \n",
    "          'mean: %2.4f, %2.4f'%(np.mean(accepted_inputs_scalar[:,0]), np.mean(accepted_inputs_scalar[:,1])), \n",
    "          'sd: %2.4f, %2.4f'%(np.std(accepted_inputs_scalar[:,0]), np.std(accepted_inputs_scalar[:,1])) )\n",
    "    \n",
    "    \n",
    "    ########## PLOTTING ################\n",
    "    fig, axs = plt.subplots(ncols=3, nrows=3, figsize=(15,15))\n",
    "    \n",
    "    # handles if you want to reorient figures \n",
    "#     vv_contours = axs[0,0] # first option \n",
    "#     vs_contours = axs[0,1]\n",
    "#     vv_data_1 = axs[0,2]\n",
    "#     vv_data_2 = axs[1,2]\n",
    "#     vv_post = axs[1,0]\n",
    "#     vs_post = axs[1,1]\n",
    "#     vv_post_marg = axs[2,0]\n",
    "#     vs_post_marg = axs[2,1]    \n",
    "#     vs_pf = axs[2,2]\n",
    "\n",
    "    vv_contours = axs[1,1] # second option \n",
    "    vv_data_1 = axs[0,0]\n",
    "    vv_data_2 = axs[0,1]\n",
    "    vv_post_marg = axs[1,0] # fills upper left quadrant\n",
    "    \n",
    "    vs_contours = axs[1,2]\n",
    "    vs_pf = axs[0,2]\n",
    "    \n",
    "    vv_post = axs[2,1]\n",
    "    vs_post = axs[2,2]\n",
    "    \n",
    "    vs_post_marg = axs[2,0]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x = input_samples[:,0] \n",
    "    y = input_samples[:,1]\n",
    "    xs = accepted_inputs_scalar[:,0]\n",
    "    ys = accepted_inputs_scalar[:,1]\n",
    "\n",
    "    xv = accepted_inputs_vector[:,0]\n",
    "    yv = accepted_inputs_vector[:,1]\n",
    "    \n",
    "    \n",
    "    # CONTOURS FOR FORWARD MAP\n",
    "    vv_contours.tricontour(x, y, output_samples_vector_valued[:,0], num_levels, cmap=color_map,\n",
    "                          vmin=vmin, vmax=vmax)\n",
    "    vv_contours.tricontour(x, y, output_samples_vector_valued[:,1], num_levels, cmap=color_map,\n",
    "                          vmin=vmin, vmax=vmax)\n",
    "    vs_contours.tricontour(x, y, output_samples_scalar_valued, num_levels, cmap=color_map,\n",
    "                          vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    vv_contours.set_title('Parameter Space with Contours\\nof Vector-Valued QoI Map', fontsize=fsize)\n",
    "    vs_contours.set_title('Parameter Space with Contours\\nof Scalar-Valued QoI Map', fontsize=fsize)\n",
    "    \n",
    "    \n",
    "    # MESH PLOT\n",
    "    vpost = p_set_vector.ratio*s_input_set.dist.pdf(input_samples)\n",
    "    spost = p_set_scalar.ratio*s_input_set.dist.pdf(input_samples)\n",
    "    vv_post.tricontourf(x, y, vpost, int(num_levels/2), cmap=color_map,\n",
    "                          vmin=vmin, vmax=vmax)\n",
    "    vs_post.tricontourf(x, y, spost, int(num_levels/2), cmap=color_map,\n",
    "                          vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    # CONTOURS OF TRUE POSTERIOR\n",
    "    post_pdf = sstats.multivariate_normal.pdf(input_samples, mean=post_mean, cov=post_cov, allow_singular=True)\n",
    "    vv_post.tricontour(x, y, post_pdf, int(num_levels/2), cmap='Greys', \n",
    "                        vmin=vmin, vmax=vmax, alpha=true_posterior_alpha)\n",
    "    vs_post.tricontour(x, y, post_pdf, int(num_levels/2), cmap='Greys', \n",
    "                        vmin=vmin, vmax=vmax, alpha=true_posterior_alpha)\n",
    "    prior_pdf = sstats.multivariate_normal.pdf(input_samples, mean=prior_mean, cov=prior_cov, allow_singular=True)\n",
    "    \n",
    "    # PRIOR CONTOURS\n",
    "    vv_contours.tricontour(x, y, prior_pdf, int(num_levels/2), cmap='Greys', \n",
    "                        vmin=vmin, vmax=vmax, alpha=prior_alpha)\n",
    "    vs_contours.tricontour(x, y, prior_pdf, int(num_levels/2), cmap='Greys', \n",
    "                        vmin=vmin, vmax=vmax, alpha=prior_alpha)\n",
    "    \n",
    "    vv_post.set_title('Posterior Distribution for\\nVector-Valued Approach', fontsize=fsize)\n",
    "    vs_post.set_title('Posterior Distribution for\\nScalar-Valued Approach', fontsize=fsize)\n",
    "    \n",
    "    # ERRORS \n",
    "    vdist = np.linalg.norm(vpost-post_pdf,1)\n",
    "    sdist = np.linalg.norm(spost-post_pdf,1)\n",
    "    bdist = np.linalg.norm(spost-vpost,1)\n",
    "    print('L-1 error: %2.2e vector | %2.2e scalar | %2.2e each'%(vdist, sdist, bdist))\n",
    "    \n",
    "    # FIX AXES TO BE THE SAME\n",
    "    vv_post.axis([-pbound, pbound, -pbound, pbound])\n",
    "    vs_post.axis([-pbound, pbound, -pbound, pbound])\n",
    "    vv_contours.axis([-pbound, pbound, -pbound, pbound])\n",
    "    vs_contours.axis([-pbound, pbound, -pbound, pbound])\n",
    "    \n",
    "    vv_contours.scatter(lam_true[0], lam_true[1], 100, 'k') # plot true input to compare\n",
    "    vs_contours.scatter(lam_true[0], lam_true[1], 100, 'k')\n",
    "    print(obs_data_noisy)\n",
    "    vv_contours.scatter(obs_data_noisy[0], obs_data_noisy[1], 100, 'r') # plot noisy data to compare\n",
    "    vs_contours.scatter(obs_data_noisy[0], obs_data_noisy[1], 100, 'r')\n",
    "    \n",
    "    # SHOW TRUTH AS WHITE DOT WITH BLACK BORDER\n",
    "    vv_post.scatter(lam_true[0], lam_true[1], 100, 'k')\n",
    "    vs_post.scatter(lam_true[0], lam_true[1], 100, 'k')\n",
    "    vv_post.scatter(lam_true[0], lam_true[1], 60, 'w')\n",
    "    vs_post.scatter(lam_true[0], lam_true[1], 60, 'w')\n",
    "    \n",
    "    # SCATTERPLOT ACCEPTED SAMPLES\n",
    "#     vv_post.scatter(xv, yv, color='w', alpha=0.5)\n",
    "#     vs_post.scatter(xs, ys, color='w', alpha=0.5)\n",
    "\n",
    " \n",
    "    \n",
    "    # PLOT PUSH-FORWARD AND OBSERVED FOR SCALAR MAP\n",
    "    \n",
    "    xx = np.linspace(0, 20, num_plot_pts)\n",
    "    vs_pf.plot(xx, p_set_scalar.pushforward_dist.pdf(xx), label='Push-forward of Prior')\n",
    "    vs_pf.plot(xx, p_set_scalar.observed_dist.pdf(xx), label='Observed (Gamma) Density')\n",
    "    vs_pf.legend()\n",
    "    vs_pf.set_title('Data Space for\\n$q = [(q_1-o_1)^2 + (q_2-o_2)^2]/2\\sigma_e^2$', fontsize=fsize)\n",
    "    \n",
    "    # PLOT DATA FOR VECTORS\n",
    "    rht, kht = 0.25, 2.5 # red height, black height (for vertical lines)\n",
    "    rlw, klw = 3, 1 # red line weight, black line weight\n",
    "    xx = np.linspace(-dbound, dbound, num_plot_pts)\n",
    "    vv_data_1.plot(xx, sstats.distributions.norm.pdf(xx,loc=obs_data_noisy[0],scale=data_std), \n",
    "                  color='blue', ls='-', label='$q_1$')\n",
    "    vv_data_2.plot(xx, sstats.distributions.norm.pdf(xx,loc=obs_data_noisy[1], scale=data_std), \n",
    "                  color='orange', ls='--', label='$q_2$')\n",
    "    vv_data_1.vlines(obs_data_noisy[0], 0, rht, 'r', lw=rlw)\n",
    "    vv_data_2.vlines(obs_data_noisy[1], 0, rht, 'r', lw=rlw) \n",
    "    \n",
    "    vv_data_1.vlines(obs_data[0], 0, kht, 'k', lw=klw)\n",
    "    vv_data_2.vlines(obs_data[1], 0, kht, 'k', lw=klw)\n",
    "    \n",
    "    vv_data_1.axis([-dbound, dbound, 0, 2.5])\n",
    "    vv_data_2.axis([-dbound, dbound, 0, 2.5])\n",
    "    \n",
    "    vv_data_2.set_title('Data Space for $q_2$', fontsize=fsize)\n",
    "    vv_data_1.set_title('Data Space for $q_1$', fontsize=fsize)\n",
    "    \n",
    "    \n",
    "    # PLOTTING MARGINALS (both on same axis)\n",
    "    xxx = np.linspace(-pbound, pbound,num_plot_pts)\n",
    "    XX, YY = np.meshgrid(xxx,xxx)\n",
    "    lam = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    zzs = p_set_scalar.evaluate_posterior(lam)\n",
    "    zzs = zzs.reshape(num_plot_pts,num_plot_pts)\n",
    "    if normalize_marginals:\n",
    "        zzs = zzs/np.sum(zzs)\n",
    "    marg_sx = np.sum(zzs, axis=0)\n",
    "    marg_sy = np.sum(zzs, axis=1)\n",
    "    line0, = vs_post_marg.plot(xxx, marg_sx,  color='blue', ls='-', lw=2, label='$\\\\lambda_1$ Marginal')\n",
    "    line1, = vs_post_marg.plot(xxx, marg_sy, color='orange', ls='--', lw=2, label='$\\\\lambda_2$ Marginal')\n",
    "    vs_post_marg.legend()\n",
    "    vs_post_marg.set_title('Posterior Marginals for\\nScalar-Valued Approach', fontsize=fsize)\n",
    "    \n",
    "    zzv = p_set_vector.evaluate_posterior(lam)\n",
    "    zzv = zzv.reshape(num_plot_pts,num_plot_pts)\n",
    "    if normalize_marginals:\n",
    "        zzv = zzv/np.sum(zzv)\n",
    "    marg_vx = np.sum(zzv, axis=0)\n",
    "    marg_vy = np.sum(zzv, axis=1)\n",
    "    line3, = vv_post_marg.plot(xxx, marg_vx,  color='blue', ls='-',  lw=2, label='$\\\\lambda_1$ Marginal')\n",
    "    line4, = vv_post_marg.plot(xxx, marg_vy, color='orange', ls='--', lw=2, label='$\\\\lambda_2$ Marginal')\n",
    "    vv_post_marg.legend()\n",
    "    vv_post_marg.set_title('Posterior Marginals for\\nVector-Valued Approach', fontsize=fsize)\n",
    "    \n",
    "    \n",
    "        \n",
    "    # slices through middle\n",
    "    if show_slice:\n",
    "        lines1, = vs_post_marg.plot(xxx, zzs[int(num_plot_pts/2),:], '-', lw=3) # lam 1\n",
    "        lines2, = vs_post_marg.plot(xxx, zzs[:,int(num_plot_pts/2)], ':', lw=3) # lam 2\n",
    "        linev1, = vv_post_marg.plot(xxx, zzv[int(num_plot_pts/2),:], '-', lw=3) # lam 1\n",
    "        linev2, = vv_post_marg.plot(xxx, zzv[:,int(num_plot_pts/2)], ':', lw=3) # lam 2\n",
    "        maxht = 10\n",
    "    \n",
    "    # VERTICAL LINE FOR TRUE VALUE\n",
    "    vv_post_marg.vlines(lam_true[0],0,vline_ht, 'k', lw=1)\n",
    "    vv_post_marg.vlines(lam_true[1],0,vline_ht, 'k', lw=1)\n",
    "    vs_post_marg.vlines(lam_true[0],0,vline_ht, 'k', lw=1)\n",
    "    vs_post_marg.vlines(lam_true[1],0,vline_ht, 'k', lw=1)\n",
    "    vs_post_marg.axis([-pbound, pbound, 0, maxht])\n",
    "    vv_post_marg.axis([-pbound, pbound, 0, maxht])\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "#     for ax in axs.flat:\n",
    "    vv_contours.set_xticklabels([])\n",
    "    vv_contours.set_yticklabels([])\n",
    "    vs_contours.set_xticklabels([])\n",
    "    vs_contours.set_yticklabels([])\n",
    "    vs_post.set_xticklabels([])\n",
    "    vs_post.set_yticklabels([])\n",
    "#     vs_post.label_outer()\n",
    "    plt.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormaps = ['viridis', 'plasma', 'inferno', 'magma', 'jet', \n",
    "             'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds',\n",
    "            'YlOrBr', 'YlOrRd', 'PuRd', 'RdPu', 'BuPu', 'GnBu', 'YlGnBu']\n",
    "\n",
    "out = wd.interactive(compare, \n",
    "            num_samples = wd.IntSlider(value=1000, min=100, max=5000, step=100, continuous_update=False, description=r'N'), \n",
    "            skew = wd.FloatSlider(value=1.0, min=1.0, max=2.0, step=0.05, continuous_update=False, description=r'skewness', orientation='horizontal'), \n",
    "            prior_x = wd.FloatSlider(value=0.0, min=-0.25, max=0.25, step=0.05, continuous_update=False, description=r'$\\mu_{\\lambda_1}$'), \n",
    "            prior_y = wd.FloatSlider(value=0.0, min=-0.25, max=0.25, step=0.05, continuous_update=False, description=r'$\\mu_{\\lambda_2}$'),             \n",
    "            prior_std = wd.FloatSlider(value=0.5, min=0.5, max=1.0, step=0.05, continuous_update=False, description=r'$\\sigma_\\lambda$'), \n",
    "            data_std = wd.FloatSlider(value=0.25, min=0.05, max=0.5, step=0.01, continuous_update=False, description=r'$\\sigma_e$'), \n",
    "            color_map = wd.Dropdown(value='viridis', options=colormaps, description=r'color map'), \n",
    "            num_levels = wd.IntSlider(value=40, min=10, max=50, step=5, continuous_update=False, description=r'colors'),\n",
    "            seed = wd.IntSlider(value=0, min=0, max=1000, step=1, continuous_update=False, description=r'seed', orientation='horizontal') )\n",
    "\n",
    "children = out.children\n",
    "seed = children[8] # widget handle for convenience\n",
    "skew = children[1]\n",
    "gui_2 = wd.VBox([children[7], children[6], wd.Label(r'Change the Conditioning and Data Value Below'), skew, seed])\n",
    "gui_1 = wd.VBox([children[0], children[2], children[3], children[4], children[5]])\n",
    "gui = wd.HBox([gui_1, gui_2])\n",
    "# gui_list = wd.VBox([children[i] for i in range(9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaebb4a0c65749b0ba74c02caa175cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(IntSlider(value=1000, continuous_update=False, description='N', m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%capture output\n",
    "# # out = wd.interact(compare)\n",
    "box = wd.VBox([gui, children[-1]])\n",
    "seed.value = 2 # move the seed to trigger a run\n",
    "box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias prior away from observation and lower its variance. Make the data very uncertain. \n",
    "The MSE approach handles this well, while error starts to pollute the vector-valued approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness (squared) acts like condition number (asymptotically) for this particular QoI map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97ffed84adf404ab000d849d0d63fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.1, description='max_skew', max=10.0, min=1.1), Checkbox(value=False,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def skewwrap(max_skew=2, res=1000, log=False):\n",
    "    skewness = np.linspace(1,max_skew,res)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    condition = []\n",
    "    for skew in skewness:\n",
    "        condition.append( np.linalg.cond(skewmat(skew)) )\n",
    "    plt.plot(skewness, condition, label='condition number')\n",
    "    plt.plot(skewness, skewness**2, label=r'skewness$^2$')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "        plt.xscale('log')\n",
    "    plt.ylabel('condition number',fontsize=18)\n",
    "    plt.xlabel('skewness',fontsize=18)\n",
    "    plt.title(\"skewness and condition number\",fontsize=24)\n",
    "    plt.legend(fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "wd.interactive(skewwrap, max_skew=wd.FloatSlider(min=1.1,max=10), res=wd.fixed(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
