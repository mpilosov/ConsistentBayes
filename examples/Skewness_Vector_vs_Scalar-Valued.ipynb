{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbayes.sample\n",
    "import cbayes.distributions\n",
    "import cbayes.solve\n",
    "import numpy as np\n",
    "import ipywidgets as wd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sstats\n",
    "import scipy.spatial as spat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following linear map $Q_s: \\mathbb{R}^2 \\to \\mathbb{R}^2$ is defined to have skewness $s$ at all $\\lambda \\in \\Lambda$.  \n",
    "\n",
    "$$\n",
    "Q_s(\\lambda) = \\lbrace \\, \\lambda_1, \\; \\lambda_1 \\sqrt{s^2 - 1} + \\lambda_2 \\, \\rbrace\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Identities\n",
    "Let $\\lambda$ denote an arbitrary Gaussian random variable with mean $\\mu_\\lambda$ and covariance $\\Sigma_\\lambda$,\n",
    "$$\n",
    "\\lambda \\sim N\\left(\\mu_\\lambda, \\Sigma_\\lambda\\right).\n",
    "$$\n",
    "Then, for a matrix $A$, \n",
    "$$\n",
    "A\\lambda \\sim N\\left(A\\mu_\\lambda,\\, A\\Sigma_\\lambda A^T\\right)\n",
    "$$\n",
    "Let $\\eta = A\\lambda + e$, where $e\\sim N(0,\\Sigma_e)$,   \n",
    "then the posterior $p(\\lambda | \\eta)$ is given by\n",
    "\n",
    "$$\n",
    "p(\\lambda | \\eta=\\bar{\\eta}) = N\\left(\\hat{\\mu}, \\hat{\\Sigma}\\right),\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\hat{\\mu} = \\mu_\\lambda + \\Sigma_\\lambda A^T\\left(A\\Sigma_\\lambda A^T + \\Sigma_e\\right)^{-1}\\left(\\bar{\\eta} - A\\mu_\\lambda\\right)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\hat{\\Sigma} = \\Sigma_\\lambda - \\Sigma_\\lambda A^T\\left(A\\Sigma_\\lambda A^T + \\Sigma_e\\right)^{-1}A\\Sigma_\\lambda\n",
    "$$\n",
    "\n",
    "[These notes](https://cs.nyu.edu/~roweis/notes/gaussid.pdf) by Sam Roweis also provide some useful identities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function that generates an arbitrarily ill-condidtioned 2-2 map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(skew):\n",
    "    # this function makes a linear map whos first component is the x-unit vector\n",
    "    # and each subsequent component is a norm-1 vector satisfying the property\n",
    "    # that the 2-2 map made from it and the aforementioned unit vector is a map\n",
    "    # with skewness in skew_range, which is a list of desired skewnesses   \n",
    "    # TODO currently this map only works for 2-D input space     \n",
    "    \n",
    "    def my_model(parameter_samples):\n",
    "        Q_map = skewmat(skew)\n",
    "        QoI_samples = np.dot(parameter_samples, np.transpose(Q_map))\n",
    "#         QoI_samples = Q_map@parameter_samples.T\n",
    "        return QoI_samples\n",
    "    return my_model\n",
    "\n",
    "def skewmat(skew):\n",
    "    Q_map = [ [1.0, 0.0] ] # all map components have the same norm, rect_size to have measures of events equal btwn spaces.\n",
    "    Q_map.append( [np.sqrt(skew**2 - 1), 1] ) # taken with the first component, this leads to a 2-2 map with skewsness 's'\n",
    "    Q_map = np.array( Q_map )\n",
    "    return Q_map\n",
    "\n",
    "def gauss_sol(prior_mean, prior_std, data_std, A, data):\n",
    "    if type(prior_mean) is int:\n",
    "        prior_mean = [prior_mean, prior_mean]\n",
    "    if type(prior_mean) is float:\n",
    "        prior_mean = [prior_mean, prior_mean]\n",
    "    if type(prior_mean) is list:\n",
    "        prior_mean = np.array(prior_mean).reshape(-1,1)\n",
    "    if type(prior_std) is list:\n",
    "        prior_std = np.array(prior_std).reshape(-1,1)\n",
    "    if type(data_std) is list:\n",
    "        data_std = np.array(data_std).reshape(-1,1)\n",
    "    prior_cov = prior_std*prior_std*np.eye(2) \n",
    "    data_cov = data_std*data_std*np.eye(2) \n",
    "    \n",
    "    ASA = A@prior_cov@A.T\n",
    "    \n",
    "    precision = np.linalg.inv(ASA + data_cov)\n",
    "    kahlman_update = (prior_cov@A.T@precision)\n",
    "    post_mean = prior_mean + kahlman_update@(data - A@prior_mean)\n",
    "    post_cov = prior_cov - kahlman_update@A@prior_cov\n",
    "    \n",
    "    return prior_mean, prior_cov, post_mean, post_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Analytical Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = skewmat(1.01)\n",
    "# # print(A)\n",
    "# data_std = 0.25\n",
    "# prior_std = 1\n",
    "# prior_mean = 0\n",
    "# lam_true = np.array([0.0, 0.0])\n",
    "# obs_data = A@lam_true.T + data_std*np.random.randn(2)\n",
    "\n",
    "# prior_mean, prior_cov, post_mean, post_cov = gauss_sol(prior_mean, prior_std, data_std, A, obs_data.reshape(-1,1) )\n",
    "# print(post_mean.T,'\\n')\n",
    "# print(post_cov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the contours of this vector-valued map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate samples and map them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(num_samples=5000, skew=1, prior_x=0.0, prior_y=0.0, prior_std = 1.0, data_std = 0.25, color_map = 'jet', num_levels = 40, seed=12):\n",
    "    model = make_model(skew)\n",
    "    lam_true = np.array([0.0, 0.0])\n",
    "    obs_data = model(lam_true)\n",
    "    np.random.seed(seed)\n",
    "    obs_data_noisy = obs_data + data_std*np.random.randn(2)\n",
    "    mse_fun = cbayes.sample.MSE_generator(model, obs_data_noisy, data_std)\n",
    "    \n",
    "    # ANALYTICAL SOLUTION\n",
    "    prior_mean = np.array([prior_x, prior_y])\n",
    "    A = skewmat(skew)\n",
    "    prior_mean, prior_cov, post_mean, post_cov = gauss_sol(prior_mean, prior_std, data_std, A, obs_data_noisy)\n",
    "\n",
    "    s_input_set = cbayes.sample.sample_set(size=(num_samples, 2))\n",
    "    s_input_set.set_dist(dim=0, distribution='normal', kwds={'loc': prior_mean[0], 'scale': prior_std})\n",
    "    s_input_set.set_dist(dim=1, distribution='normal', kwds={'loc': prior_mean[1], 'scale': prior_std})\n",
    "    input_samples = s_input_set.generate_samples(seed=seed)\n",
    "    \n",
    "    output_samples_vector_valued = model(input_samples)\n",
    "    output_samples_scalar_valued = mse_fun(input_samples)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # VECTOR PROBLEM\n",
    "    s_output_set_vector_valued = cbayes.sample.sample_set(size=(num_samples, 2))\n",
    "    s_output_set_vector_valued.samples = output_samples_vector_valued\n",
    "    p_set_vector = cbayes.sample.problem_set(s_input_set, s_output_set_vector_valued)\n",
    "    # Set observed \n",
    "    p_set_vector.set_observed_dist(dim=0, dist='normal', \n",
    "                                   kwds={'loc': obs_data_noisy[0], 'scale': data_std})\n",
    "    p_set_vector.set_observed_dist(dim=1, dist='normal', \n",
    "                                   kwds={'loc': obs_data_noisy[1], 'scale': data_std})\n",
    "    p_set_vector.model = model\n",
    "    \n",
    "    p_set_vector.compute_pushforward_dist()\n",
    "    p_set_vector.set_ratio()\n",
    "    \n",
    "    cbayes.solve.problem(p_set_vector)\n",
    "    accepted_inputs_vector = p_set_vector.input.samples[p_set_vector.accept_inds,:]\n",
    "    print('num accepted for vector-valued:', len(accepted_inputs_vector), \n",
    "          'mean: %2.4f, %2.4f'%(np.mean(accepted_inputs_vector[:,0]), np.mean(accepted_inputs_vector[:,1])), \n",
    "          'sd: %2.4f, %2.4f'%(np.std(accepted_inputs_vector[:,0]), np.std(accepted_inputs_vector[:,1])) )\n",
    "\n",
    "    # SCALAR PROBLEM\n",
    "    s_output_set_scalar_valued = cbayes.sample.sample_set(size=(num_samples, 1))\n",
    "    s_output_set_scalar_valued.samples = output_samples_scalar_valued\n",
    "    p_set_scalar = cbayes.sample.problem_set(s_input_set, s_output_set_scalar_valued)\n",
    "    # Set observed \n",
    "    num_observations = 2 # NOT TO BE CHANGED\n",
    "    p_set_scalar.set_observed_dist('gamma', {'a':num_observations/2.0, 'scale':2.0/num_observations}, dim=0)\n",
    "    p_set_scalar.model = mse_fun\n",
    "    \n",
    "    p_set_scalar.compute_pushforward_dist()\n",
    "    p_set_scalar.set_ratio()\n",
    "    \n",
    "    cbayes.solve.problem(p_set_scalar)\n",
    "    accepted_inputs_scalar = p_set_scalar.input.samples[p_set_scalar.accept_inds,:]\n",
    "    print('num accepted for scalar-valued:', len(accepted_inputs_scalar), \n",
    "          'mean: %2.4f, %2.4f'%(np.mean(accepted_inputs_scalar[:,0]), np.mean(accepted_inputs_scalar[:,1])), \n",
    "          'sd: %2.4f, %2.4f'%(np.std(accepted_inputs_scalar[:,0]), np.std(accepted_inputs_scalar[:,1])) )\n",
    "    \n",
    "    # PLOTTING\n",
    "    fig, axs = plt.subplots(ncols=3, nrows=3, figsize=(15,15))\n",
    "    \n",
    "    x = input_samples[:,0] \n",
    "    y = input_samples[:,1]\n",
    "    xs = accepted_inputs_scalar[:,0]\n",
    "    ys = accepted_inputs_scalar[:,1]\n",
    "\n",
    "    xv = accepted_inputs_vector[:,0]\n",
    "    yv = accepted_inputs_vector[:,1]\n",
    "    \n",
    "    \n",
    "    # CONTOURS FOR FORWARD MAP\n",
    "    axs[0,0].tricontour(x, y, output_samples_vector_valued[:,0], num_levels, cmap=color_map)\n",
    "    axs[0,0].tricontour(x, y, output_samples_vector_valued[:,1], num_levels, cmap=color_map)\n",
    "    axs[0,1].tricontour(x, y, output_samples_scalar_valued, num_levels, cmap=color_map)\n",
    "    \n",
    "    # MESH PLOT\n",
    "    vmin, vmax = 0, None\n",
    "    vpost = p_set_vector.ratio*s_input_set.dist.pdf(input_samples)\n",
    "    spost = p_set_scalar.ratio*s_input_set.dist.pdf(input_samples)\n",
    "    axs[1,0].tricontourf(x, y, vpost, int(num_levels/2), cmap=color_map,\n",
    "                          vmin=vmin, vmax=vmax)\n",
    "    axs[1,1].tricontourf(x, y, spost, int(num_levels/2), cmap=color_map,\n",
    "                          vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    # CONTOURS OF TRUE POSTERIOR\n",
    "    post_pdf = sstats.multivariate_normal.pdf(input_samples, mean=post_mean, cov=post_cov, allow_singular=True)\n",
    "    axs[1,0].tricontour(x, y, post_pdf, int(num_levels/2), cmap='Greys', \n",
    "                        vmin=vmin, vmax=vmax, alpha=0.25)\n",
    "    axs[1,1].tricontour(x, y, post_pdf, int(num_levels/2), cmap='Greys', \n",
    "                        vmin=vmin, vmax=vmax, alpha=0.25)\n",
    "    prior_pdf = sstats.multivariate_normal.pdf(input_samples, mean=prior_mean, cov=prior_cov, allow_singular=True)\n",
    "    \n",
    "    # PRIOR CONTOURS\n",
    "    axs[0,0].tricontour(x, y, prior_pdf, int(num_levels/2), cmap='Greys', \n",
    "                        vmin=vmin, vmax=vmax, alpha=0.25)\n",
    "    axs[0,1].tricontour(x, y, prior_pdf, int(num_levels/2), cmap='Greys', \n",
    "                        vmin=vmin, vmax=vmax, alpha=0.25)\n",
    "    \n",
    "    # ERRORS \n",
    "    vdist = np.linalg.norm(vpost-post_pdf,1)\n",
    "    sdist = np.linalg.norm(spost-post_pdf,1)\n",
    "    bdist = np.linalg.norm(spost-vpost,1)\n",
    "    print('L-1 error: %2.2e vector | %2.2e scalar | %2.2e each'%(vdist, sdist, bdist))\n",
    "\n",
    "    \n",
    "    bound_val = 1.0\n",
    "    axs[0,0].axis([-bound_val, bound_val, -bound_val, bound_val])\n",
    "    axs[0,1].axis([-bound_val, bound_val, -bound_val, bound_val])\n",
    "    axs[1,0].axis([-bound_val, bound_val, -bound_val, bound_val])\n",
    "    axs[1,1].axis([-bound_val, bound_val, -bound_val, bound_val])\n",
    "    axs[0,0].scatter(lam_true[0], lam_true[1], 100, 'k') # plot true value to compare\n",
    "    axs[0,1].scatter(lam_true[0], lam_true[1], 100, 'k')\n",
    "\n",
    "    axs[0,0].scatter(obs_data_noisy[0], obs_data_noisy[1], 100, 'r') # plot true value to compare\n",
    "    axs[0,1].scatter(obs_data_noisy[0], obs_data_noisy[1], 100, 'r')\n",
    "    \n",
    "    # SHOW TRUTH AS WHITE DOT WITH BLACK BORDER\n",
    "    axs[1,0].scatter(lam_true[0], lam_true[1], 100, 'k')\n",
    "    axs[1,1].scatter(lam_true[0], lam_true[1], 100, 'k')\n",
    "    axs[1,0].scatter(lam_true[0], lam_true[1], 60, 'w')\n",
    "    axs[1,1].scatter(lam_true[0], lam_true[1], 60, 'w')\n",
    "    \n",
    "    # SCATTERPLOT ACCEPTED SAMPLES\n",
    "#     axs[1,0].scatter(xv, yv, color='w', alpha=0.5)\n",
    "#     axs[1,1].scatter(xs, ys, color='w', alpha=0.5)\n",
    "    \n",
    "    # PLOT PUSH-FORWARD AND OBSERVED FOR SCALAR MAP\n",
    "    num_plot_pts = 100\n",
    "    xx = np.linspace(0, 20, num_plot_pts)\n",
    "    X, Y = np.meshgrid(xx,xx)\n",
    "    D = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    axs[2,2].plot(xx, p_set_scalar.pushforward_dist.pdf(xx))\n",
    "    axs[2,2].plot(xx, p_set_scalar.observed_dist.pdf(xx))\n",
    "    \n",
    "    # PLOT DATA FOR VECTORS\n",
    "    xx = np.linspace(-2.0, 2.0, num_plot_pts)\n",
    "    axs[0,2].plot(xx, sstats.distributions.norm.pdf(xx,loc=obs_data_noisy[0],scale=data_std), \n",
    "                  color='blue', ls='-', label='$q_1$')\n",
    "    axs[1,2].plot(xx, sstats.distributions.norm.pdf(xx,loc=obs_data_noisy[1], scale=data_std), \n",
    "                  color='orange', ls='--', label='$q_2$')\n",
    "    axs[0,2].vlines(obs_data_noisy[0], 0, 1, 'r', lw=1)\n",
    "    axs[0,2].vlines(obs_data[0], 0, 0.5, 'k', lw=1)\n",
    "    axs[1,2].vlines(obs_data[1], 0, 0.5, 'k', lw=1)\n",
    "    axs[1,2].vlines(obs_data_noisy[1], 0, 1, 'r', lw=1)\n",
    "    \n",
    "    \n",
    "    xxx = np.linspace(-bound_val, bound_val,num_plot_pts)\n",
    "    XX, YY = np.meshgrid(xxx,xxx)\n",
    "    lam = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "    normalize_marginals = False\n",
    "    # PLOTTING MARGINALS (both on same axis)\n",
    "    zzs = p_set_scalar.evaluate_posterior(lam)\n",
    "    zzs = zzs.reshape(num_plot_pts,num_plot_pts)\n",
    "    if normalize_marginals:\n",
    "        zzs = zzs/np.sum(zzs)\n",
    "    marg_sx = np.sum(zzs, axis=0)\n",
    "    marg_sy = np.sum(zzs, axis=1)\n",
    "    line0, = axs[2,1].plot(xxx, marg_sx,  color='blue', ls='-', lw=2)\n",
    "    line1, = axs[2,1].plot(xxx, marg_sy, color='orange', ls='--', lw=2)\n",
    "    plt.legend([line0, line1], ['$\\\\lambda_1$', '$\\\\lambda_2$' ])\n",
    "    \n",
    "    zzv = p_set_vector.evaluate_posterior(lam)\n",
    "    zzv = zzv.reshape(num_plot_pts,num_plot_pts)\n",
    "    if normalize_marginals:\n",
    "        zzv = zzv/np.sum(zzv)\n",
    "    marg_vx = np.sum(zzv, axis=0)\n",
    "    marg_vy = np.sum(zzv, axis=1)\n",
    "    line3, = axs[2,0].plot(xxx, marg_vx,  color='blue', ls='-',  lw=2)\n",
    "    line4, = axs[2,0].plot(xxx, marg_vy, color='orange', ls='--', lw=2)\n",
    "    plt.legend([line3, line4], ['$\\\\lambda_1$', '$\\\\lambda_2$' ])\n",
    "    \n",
    "    if normalize_marginals:\n",
    "        maxht = 0.15\n",
    "        vline_ht = 0.05 \n",
    "    else:\n",
    "        maxht = 350\n",
    "        vline_ht = 100 # shows truth\n",
    "        \n",
    "    # slices through middle\n",
    "    show_slice = False\n",
    "    if show_slice:\n",
    "        lines1, = axs[2,1].plot(xxx, zzs[int(num_plot_pts/2),:], '-', lw=3) # lam 1\n",
    "        lines2, = axs[2,1].plot(xxx, zzs[:,int(num_plot_pts/2)], ':', lw=3) # lam 2\n",
    "        linev1, = axs[2,0].plot(xxx, zzv[int(num_plot_pts/2),:], '-', lw=3) # lam 1\n",
    "        linev2, = axs[2,0].plot(xxx, zzv[:,int(num_plot_pts/2)], ':', lw=3) # lam 2\n",
    "        maxht = 10\n",
    "    \n",
    "    # VERTICAL LINE FOR TRUE VALUE\n",
    "    axs[2,0].vlines(lam_true[0],0,vline_ht, 'k', lw=1)\n",
    "    axs[2,0].vlines(lam_true[1],0,vline_ht, 'k', lw=1)\n",
    "    axs[2,1].vlines(lam_true[0],0,vline_ht, 'k', lw=1)\n",
    "    axs[2,1].vlines(lam_true[1],0,vline_ht, 'k', lw=1)\n",
    "    axs[2,1].axis([-bound_val, bound_val, 0, maxht])\n",
    "    axs[2,0].axis([-bound_val, bound_val, 0, maxht])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdbbbae722e42679a22f87cb84f8a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1000, continuous_update=False, description='num_samples', max=5000, min=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colormaps = ['viridis', 'plasma', 'inferno', 'magma', 'jet', \n",
    "             'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds',\n",
    "            'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu',\n",
    "            'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn']\n",
    "\n",
    "out = wd.interact(compare, \n",
    "            num_samples = wd.IntSlider(value=1000, min=100, max=5000, step=100, continuous_update=False), \n",
    "            skew = wd.FloatSlider(value=1.0, min=1.0, max=2.0, step=0.05, continuous_update=False), \n",
    "            prior_x = wd.FloatSlider(value=0.0, min=-0.25, max=0.25, step=0.05, continuous_update=False), \n",
    "            prior_y = wd.FloatSlider(value=0.0, min=-0.25, max=0.25, step=0.05, continuous_update=False),             \n",
    "            prior_std = wd.FloatSlider(value=0.5, min=0.5, max=1.0, step=0.05, continuous_update=False), \n",
    "            data_std = wd.FloatSlider(value=0.25, min=0.05, max=0.5, step=0.01, continuous_update=False), \n",
    "            color_map = wd.Dropdown(value='jet', options=colormaps), \n",
    "            num_levels = wd.IntSlider(value=40, min=20, max=100, step=5, continuous_update=False),\n",
    "            seed = wd.IntSlider(value=0, min=0, max=1000, step=1, continuous_update=False) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias prior away from observation and lower its variance. Make the data very uncertain. \n",
    "The MSE approach handles this well, while error starts to pollute the vector-valued approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.widget.children[2].value = 1\n",
    "out.widget.children[2].value = -0.5\n",
    "out.widget.children[3].value = -0.5\n",
    "out.widget.children[4].value = 0.75\n",
    "out.widget.children[5].value = 0.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
